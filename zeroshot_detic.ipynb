{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vR8qtrEIS0ZK"
      },
      "source": [
        "Modified from detic demo https://colab.research.google.com/drive/1QtTW9-ukX2HKZGvt0QvVGqjuqEykoZKI "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ou8uWMGS0ZM"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7MpTaZ0YNTb"
      },
      "outputs": [],
      "source": [
        "# Install detectron2\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9ErX0ZvYYHI"
      },
      "outputs": [],
      "source": [
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "# Use the below line to install detectron2 if the above one has an error\n",
        "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.6'\n",
        "\n",
        "# clone and install Detic\n",
        "# !git clone https://github.com/facebookresearch/Detic.git --recurse-submodules\n",
        "%cd Detic\n",
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LER_mry-ZFYC"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import sys\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "#rom google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "\n",
        "# Detic libraries\n",
        "sys.path.insert(0, 'third_party/CenterNet2/')\n",
        "from centernet.config import add_centernet_config\n",
        "from detic.config import add_detic_config\n",
        "from detic.modeling.utils import reset_cls_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIpJ9klCZt_y"
      },
      "outputs": [],
      "source": [
        "# Build the detector and download our pretrained weights\n",
        "cfg = get_cfg()\n",
        "add_centernet_config(cfg)\n",
        "add_detic_config(cfg)\n",
        "cfg.merge_from_file(\"configs/Detic_LCOCOI21k_CLIP_SwinB_896b32_4x_ft4x_max-size.yaml\")\n",
        "cfg.MODEL.WEIGHTS = 'https://dl.fbaipublicfiles.com/detic/Detic_LCOCOI21k_CLIP_SwinB_896b32_4x_ft4x_max-size.pth'\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.25  # set threshold for this model\n",
        "cfg.MODEL.ROI_BOX_HEAD.ZEROSHOT_WEIGHT_PATH = 'rand'\n",
        "cfg.MODEL.ROI_HEADS.ONE_CLASS_PER_PROPOSAL = True # For better visualization purpose. Set to False for all classes.\n",
        "# cfg.MODEL.DEVICE='cpu' # uncomment this to use cpu-only mode.\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKToy2hSkiqH"
      },
      "outputs": [],
      "source": [
        "# Setup the model's vocabulary using build-in datasets\n",
        "\n",
        "BUILDIN_CLASSIFIER = {\n",
        "    'lvis': 'datasets/metadata/lvis_v1_clip_a+cname.npy',\n",
        "    'objects365': 'datasets/metadata/o365_clip_a+cnamefix.npy',\n",
        "    'openimages': 'datasets/metadata/oid_clip_a+cname.npy',\n",
        "    'coco': 'datasets/metadata/coco_clip_a+cname.npy',\n",
        "}\n",
        "\n",
        "BUILDIN_METADATA_PATH = {\n",
        "    'lvis': 'lvis_v1_val',\n",
        "    'objects365': 'objects365_v2_val',\n",
        "    'openimages': 'oid_val_expanded',\n",
        "    'coco': 'coco_2017_val',\n",
        "}\n",
        "\n",
        "vocabulary = 'lvis' # change to 'lvis', 'objects365', 'openimages', or 'coco'\n",
        "metadata = MetadataCatalog.get(BUILDIN_METADATA_PATH[vocabulary])\n",
        "classifier = BUILDIN_CLASSIFIER[vocabulary]\n",
        "num_classes = len(metadata.thing_classes)\n",
        "reset_cls_test(predictor.model, classifier, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsxu6uFnS0ZP"
      },
      "source": [
        "# Detic demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5pVXciWZhTS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Download a sample image and display. Replace path here to try your own images!\n",
        "#!wget https://web.eecs.umich.edu/~fouhey/fun/desk/desk.jpg\n",
        "im = cv2.imread(\"/home/akirchme/coursework/16824/project/Detic/input.jpg\")\n",
        "plt.imshow(im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34FF6TjFl9x-"
      },
      "outputs": [],
      "source": [
        "# Run model and show results\n",
        "outputs = predictor(im)\n",
        "v = Visualizer(im[:, :, ::-1], metadata)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20, 20))\n",
        "ax.imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi8kK4pPS0ZP"
      },
      "outputs": [],
      "source": [
        "outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3S511ZZS0ZQ"
      },
      "source": [
        "# Recognize headlights + taillights "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDeCPfiomTGG"
      },
      "outputs": [],
      "source": [
        "# Change the model's vocabulary to a customized one and get their word-embedding \n",
        "#  using a pre-trained CLIP model.\n",
        "\n",
        "from detic.modeling.text.text_encoder import build_text_encoder\n",
        "def get_clip_embeddings(vocabulary, prompt='a '):\n",
        "    text_encoder = build_text_encoder(pretrain=True)\n",
        "    text_encoder.eval()\n",
        "    texts = [prompt + x for x in vocabulary]\n",
        "    emb = text_encoder(texts).detach().permute(1, 0).contiguous().cpu()\n",
        "    return emb\n",
        "  \n",
        "vocabulary = 'custom'\n",
        "metadata = MetadataCatalog.get(\"__unused18\")\n",
        "print(metadata)\n",
        "#metadata.thing_classes = ['headlight', 'taillight', 'traffic_light'] # Change here to try your own vocabularies!\n",
        "metadata.thing_classes = ['head light', 'tail light', 'turn light', 'bright'] # Change here to try your own vocabularies!\n",
        "classifier = get_clip_embeddings(metadata.thing_classes)\n",
        "num_classes = len(metadata.thing_classes)\n",
        "reset_cls_test(predictor.model, classifier, num_classes)\n",
        "# Reset visualization threshold\n",
        "output_score_threshold = 0.1\n",
        "for cascade_stages in range(len(predictor.model.roi_heads.box_predictor)):\n",
        "    predictor.model.roi_heads.box_predictor[cascade_stages].test_score_thresh = output_score_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9W9MbTbcm47m"
      },
      "outputs": [],
      "source": [
        "# Run model and show results\n",
        "outputs = predictor(im)\n",
        "v = Visualizer(im[:, :, ::-1], metadata)\n",
        "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20, 20))\n",
        "ax.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g22zS7e3I8ir"
      },
      "outputs": [],
      "source": [
        "# look at the outputs. \n",
        "# See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
        "print(outputs[\"instances\"].pred_classes) # class index\n",
        "print([metadata.thing_classes[x] for x in outputs[\"instances\"].pred_classes.cpu().tolist()]) # class names\n",
        "print(outputs[\"instances\"].scores)\n",
        "print(outputs[\"instances\"].pred_boxes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYrJsM5zS0ZX"
      },
      "source": [
        "# Load images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EIVIGkJS0ZX"
      },
      "outputs": [],
      "source": [
        "import imageio as iio\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tqdm import tqdm\n",
        "folder = '/home/akirchme/coursework/16824/project/data/samples/CAM_FRONT'\n",
        "only_files = [f'{folder}/{f}' for f in listdir(folder) if isfile(join(folder, f))]\n",
        "images = [iio.imread(f) for f in tqdm(only_files)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXEPYLYAS0ZX"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "290hg5vyS0ZX"
      },
      "outputs": [],
      "source": [
        "# Run model and show results\n",
        "out_folder = '/home/akirchme/coursework/16824/project/output_0409_pedestrian_0.10/CAM_FRONT'\n",
        "os.makedirs(out_folder, exist_ok=True) \n",
        "n_show = 10\n",
        "for i, im in tqdm(enumerate(images), total=len(images)):\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1], metadata)\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    out = out.get_image()[:, :, ::-1]\n",
        "    plt.imsave(f'{out_folder}/{i}.png', out)\n",
        "    if i < n_show:\n",
        "        fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20, 20))\n",
        "        ax.imshow(out)#cv2.cvtColor(out, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMIgWM01S0ZX"
      },
      "source": [
        "# NuScenes demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-OZfv0XS0ZX"
      },
      "outputs": [],
      "source": [
        "# from https://www.nuscenes.org/tutorials/nuscenes_tutorial.html\n",
        "\n",
        "from nuscenes.nuscenes import NuScenes\n",
        "\n",
        "data_dir = '/home/akirchme/coursework/16824/project/data'\n",
        "nusc = NuScenes(version='v1.0-mini', dataroot=data_dir, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbKcNipzS0ZX"
      },
      "outputs": [],
      "source": [
        "my_scene = nusc.scene[0]\n",
        "first_sample_token = my_scene['first_sample_token']\n",
        "my_sample = nusc.get('sample', first_sample_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTMk7oLeS0ZX"
      },
      "outputs": [],
      "source": [
        "import imageio as iio\n",
        "\n",
        "def output_image():\n",
        "    sensor = 'CAM_FRONT'\n",
        "    cam_front_data = nusc.get('sample_data', my_sample['data'][sensor])\n",
        "    if mode == 'bbox':\n",
        "        return nusc.render_sample_data(cam_front_data['token'])\n",
        "    elif mode == 'raw':\n",
        "        return iio.imread(f'{data_dir}/{cam_front_data[\"filename\"]}')\n",
        "    raise \"Unrecognized\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}